{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "from scipy.misc import imresize\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPretrainedModel(name):\n",
    "    model = load_model(name)\n",
    "    print(\"Loaded pretrained model with weights from disk\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "###Remember to change the all variables (especially weightsFile name) before executing the code.\n",
    "###############################################################################################################################\n",
    "#Directory names of the folders that contain the images that need to be trained and tested for.\n",
    "trainDir = 'Flickr27//CTrain-GreyScale'\n",
    "testDir = 'Flickr27//CValidation-GreyScale'\n",
    "\n",
    "#The list of class names for which label binarizer is run\n",
    "class_names = ['Apple', 'Fedex', 'Google']\n",
    "\n",
    "#channels = 3 ==> RGB or HSV images, channels = 1 ==> Greyscale images\n",
    "channels = 1\n",
    "\n",
    "#Normalization value should be 255 for RGB or Greyscale images. It should be 1 for HSV images.\n",
    "normalizationVal = 255.0\n",
    "\n",
    "#Pretrained Model Filename\n",
    "modelFileName = 'Models//NewIV3-150x150x1-3C.h5'\n",
    "withPreTrainedWeights = False #Greyscale model has no pretrained weights. Keep this as false.\n",
    "\n",
    "#The filename in which the output weights would be stored.\n",
    "outputWeightsFileName = 'NewIV3-150x150x1-3C-Run1.hdf5'\n",
    "\n",
    "#Other parameters\n",
    "epochs = 100\n",
    "batchsize = 32\n",
    "learningRate = 0.001\n",
    "monitorVariable = 'val_categorical_accuracy'\n",
    "monitorMode = 'max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prem Thomas Eapen\\AppData\\Roaming\\Python\\Python36\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "#Converting the images to numpy arrays\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "#For the train images\n",
    "for dirname in os.listdir(trainDir):\n",
    "    if dirname in class_names:\n",
    "        classdir = trainDir + '//' + dirname\n",
    "        for filename in os.listdir(classdir):\n",
    "            if filename.endswith('.jpg'):\n",
    "                fnWithPath = classdir + '//' + filename\n",
    "                image_data = skimage.io.imread(fnWithPath)\n",
    "                new_image_data = skimage.transform.resize(image_data,(150,150,channels))\n",
    "                new_image_data = new_image_data.reshape((1, 150, 150, channels)).astype(np.float32) / normalizationVal\n",
    "                X_train.append(new_image_data)\n",
    "                y_train.append(dirname)\n",
    "        \n",
    "#For the validation images\n",
    "for dirname in os.listdir(testDir):\n",
    "    if dirname in class_names:\n",
    "        classdir = testDir + '//' + dirname\n",
    "        for filename in os.listdir(classdir):\n",
    "            if filename.endswith('.jpg'):\n",
    "                fnWithPath = classdir + '//' + filename\n",
    "                image_data = skimage.io.imread(fnWithPath)\n",
    "                new_image_data = skimage.transform.resize(image_data,(150,150,channels))\n",
    "                new_image_data = new_image_data.reshape((1, 150, 150, channels)).astype(np.float32) / normalizationVal\n",
    "                X_test.append(new_image_data)\n",
    "                y_test.append(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129600000\n",
      "5760\n",
      "32400000\n",
      "1440\n"
     ]
    }
   ],
   "source": [
    "print(np.size(X_train))\n",
    "print(np.size(y_train)) #The total number of train images per class\n",
    "print(np.size(X_test))\n",
    "print(np.size(y_test))  #The total number of test images per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train,(np.size(y_train),150,150,channels))\n",
    "y_train = np.reshape(y_train,(np.size(y_train),1))\n",
    "X_test = np.reshape(X_test,(np.size(y_test),150,150,channels))\n",
    "y_test = np.reshape(y_test,(np.size(y_test),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = label_binarize(y_train, classes = class_names)\n",
    "y_test = label_binarize(y_test, classes = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model with weights from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = loadPretrainedModel(modelFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will run if there are pretrained weights by setting the layers as not trainable. This will be transfer learning. \n",
    "if withPreTrainedWeights:\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 150, 150, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 74, 74, 32)   288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 74, 74, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 74, 74, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 32)   9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 32)   96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 72, 72, 64)   18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 72, 72, 64)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 72, 72, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 35, 35, 64)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 35, 35, 80)   5120        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 35, 35, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 35, 35, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 33, 33, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 33, 33, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 33, 33, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 64)   12288       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 48)   9216        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 192)  0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 64)   12288       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 64)   16384       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 48)   12288       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 256)  0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 64)   16384       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 64)   18432       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 48)   13824       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 16, 16, 288)  0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 64)   18432       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 64)   18432       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 7, 7, 384)    995328      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 96)     82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 7, 7, 384)    1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 96)     288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 7, 7, 384)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 96)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 288)    0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    98304       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    98304       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 128)    114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 128)    114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 128)    384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 128)    384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 128)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 192)    147456      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 192)    172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 192)    576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 192)    576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 192)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 192)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    122880      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    122880      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 160)    179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 160)    179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 160)    480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 160)    480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 160)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 160)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 192)    147456      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 192)    215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 192)    576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 192)    576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 192)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 192)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    122880      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    122880      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 160)    179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 160)    179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 160)    480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 160)    480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 160)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 160)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 192)    147456      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 192)    215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 192)    576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 192)    576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 192)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 192)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    147456      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    147456      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 7, 7, 768)    0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 7, 7, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 192)    147456      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 7, 7, 192)    147456      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 7, 7, 192)    258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 7, 7, 192)    576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 7, 7, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 7, 7, 192)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 7, 7, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 3, 3, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 3, 3, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 3, 3, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 768)    0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 448)    573440      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    491520      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 1280)   0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 320)    409600      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 448)    917504      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    786432      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 3, 3, 2048)   0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 320)    655360      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 3, 3, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 3, 3, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 3, 3, 2048)   0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 18432)        0           dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 3)            55299       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 21,857,507\n",
      "Trainable params: 21,823,075\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if this is an addition run to the original run.\n",
    "#weightsFile = Path(outputWeightsFileName)\n",
    "#if weightsFile.is_file():\n",
    "#     model.load_weights(outputWeightsFileName)\n",
    "#     print('Weight file exists. Adding new runs.')\n",
    "# else:\n",
    "#     print('Determining the weights for the first time.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.RMSprop(lr=learningRate)\n",
    "\n",
    "model.compile(optimizer = opt, \n",
    "              loss      = 'categorical_crossentropy', \n",
    "              metrics   = ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath       = outputWeightsFileName, \n",
    "                               monitor        = monitorVariable, \n",
    "                               verbose        = 1, \n",
    "                               save_best_only = True, \n",
    "                               mode           = monitorMode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5760 samples, validate on 1440 samples\n",
      "Epoch 1/100\n",
      "5760/5760 [==============================] - 221s 38ms/step - loss: 1.4248 - categorical_accuracy: 0.5123 - val_loss: 10.7026 - val_categorical_accuracy: 0.3333\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.33333, saving model to NewIV3-150x150x1-3C-Run1.hdf5\n",
      "Epoch 2/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.8710 - categorical_accuracy: 0.6450 - val_loss: 1.0946 - val_categorical_accuracy: 0.4590\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.33333 to 0.45903, saving model to NewIV3-150x150x1-3C-Run1.hdf5\n",
      "Epoch 3/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 1.1571 - categorical_accuracy: 0.6090 - val_loss: 1.3751 - val_categorical_accuracy: 0.5236\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.45903 to 0.52361, saving model to NewIV3-150x150x1-3C-Run1.hdf5\n",
      "Epoch 4/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.9483 - categorical_accuracy: 0.6842 - val_loss: 10.4118 - val_categorical_accuracy: 0.2882\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.52361\n",
      "Epoch 5/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.7809 - categorical_accuracy: 0.7849 - val_loss: 1.2717 - val_categorical_accuracy: 0.5514\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.52361 to 0.55139, saving model to NewIV3-150x150x1-3C-Run1.hdf5\n",
      "Epoch 6/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.3610 - categorical_accuracy: 0.8950 - val_loss: 0.6260 - val_categorical_accuracy: 0.7382\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.55139 to 0.73819, saving model to NewIV3-150x150x1-3C-Run1.hdf5\n",
      "Epoch 7/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.3779 - categorical_accuracy: 0.9278 - val_loss: 0.4063 - val_categorical_accuracy: 0.8417\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.73819 to 0.84167, saving model to NewIV3-150x150x1-3C-Run1.hdf5\n",
      "Epoch 8/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.1533 - categorical_accuracy: 0.9545 - val_loss: 0.6626 - val_categorical_accuracy: 0.7007\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.84167\n",
      "Epoch 9/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.1531 - categorical_accuracy: 0.9642 - val_loss: 1.6529 - val_categorical_accuracy: 0.5396\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy did not improve from 0.84167\n",
      "Epoch 10/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0776 - categorical_accuracy: 0.9771 - val_loss: 0.5711 - val_categorical_accuracy: 0.8028\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.84167\n",
      "Epoch 11/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0931 - categorical_accuracy: 0.9823 - val_loss: 0.6620 - val_categorical_accuracy: 0.7632\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.84167\n",
      "Epoch 12/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0691 - categorical_accuracy: 0.9839 - val_loss: 0.6278 - val_categorical_accuracy: 0.7285\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.84167\n",
      "Epoch 13/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0442 - categorical_accuracy: 0.9896 - val_loss: 0.3616 - val_categorical_accuracy: 0.8903\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy improved from 0.84167 to 0.89028, saving model to NewIV3-150x150x1-3C-Run1.hdf5\n",
      "Epoch 14/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0361 - categorical_accuracy: 0.9906 - val_loss: 0.2404 - val_categorical_accuracy: 0.9299\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy improved from 0.89028 to 0.92986, saving model to NewIV3-150x150x1-3C-Run1.hdf5\n",
      "Epoch 15/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0336 - categorical_accuracy: 0.9929 - val_loss: 0.5935 - val_categorical_accuracy: 0.8083\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 16/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0373 - categorical_accuracy: 0.9917 - val_loss: 0.6497 - val_categorical_accuracy: 0.7236\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 17/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0624 - categorical_accuracy: 0.9878 - val_loss: 0.2167 - val_categorical_accuracy: 0.9264\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 18/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0294 - categorical_accuracy: 0.9941 - val_loss: 0.7911 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 19/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.1742 - categorical_accuracy: 0.9826 - val_loss: 1.2809 - val_categorical_accuracy: 0.6472\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 20/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.1015 - categorical_accuracy: 0.9878 - val_loss: 0.8730 - val_categorical_accuracy: 0.7493\n",
      "\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 21/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0485 - categorical_accuracy: 0.9929 - val_loss: 1.8235 - val_categorical_accuracy: 0.6944\n",
      "\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 22/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0561 - categorical_accuracy: 0.9910 - val_loss: 0.3555 - val_categorical_accuracy: 0.8403\n",
      "\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 23/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0326 - categorical_accuracy: 0.9950 - val_loss: 0.3603 - val_categorical_accuracy: 0.8653\n",
      "\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 24/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0221 - categorical_accuracy: 0.9960 - val_loss: 0.6872 - val_categorical_accuracy: 0.7660\n",
      "\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 25/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0283 - categorical_accuracy: 0.9939 - val_loss: 0.5510 - val_categorical_accuracy: 0.8361\n",
      "\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 26/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0335 - categorical_accuracy: 0.9953 - val_loss: 0.5870 - val_categorical_accuracy: 0.8597\n",
      "\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 27/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0481 - categorical_accuracy: 0.9932 - val_loss: 0.2455 - val_categorical_accuracy: 0.8688\n",
      "\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 28/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0449 - categorical_accuracy: 0.9943 - val_loss: 0.4221 - val_categorical_accuracy: 0.8549\n",
      "\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 29/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0228 - categorical_accuracy: 0.9946 - val_loss: 0.7168 - val_categorical_accuracy: 0.8368\n",
      "\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 30/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0113 - categorical_accuracy: 0.9972 - val_loss: 0.3203 - val_categorical_accuracy: 0.8611\n",
      "\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 31/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0116 - categorical_accuracy: 0.9970 - val_loss: 1.0793 - val_categorical_accuracy: 0.7944\n",
      "\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.92986\n",
      "Epoch 32/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0223 - categorical_accuracy: 0.9962 - val_loss: 0.2068 - val_categorical_accuracy: 0.9444\n",
      "\n",
      "Epoch 00032: val_categorical_accuracy improved from 0.92986 to 0.94444, saving model to NewIV3-150x150x1-3C-Run1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0190 - categorical_accuracy: 0.9972 - val_loss: 0.7690 - val_categorical_accuracy: 0.8646\n",
      "\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 34/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0146 - categorical_accuracy: 0.9979 - val_loss: 0.8347 - val_categorical_accuracy: 0.8979\n",
      "\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 35/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0144 - categorical_accuracy: 0.9964 - val_loss: 0.7850 - val_categorical_accuracy: 0.8604\n",
      "\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 36/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0337 - categorical_accuracy: 0.9958 - val_loss: 0.4874 - val_categorical_accuracy: 0.9201\n",
      "\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 37/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0185 - categorical_accuracy: 0.9962 - val_loss: 0.6039 - val_categorical_accuracy: 0.8819\n",
      "\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 38/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0149 - categorical_accuracy: 0.9969 - val_loss: 1.1881 - val_categorical_accuracy: 0.8972\n",
      "\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 39/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0306 - categorical_accuracy: 0.9960 - val_loss: 0.6708 - val_categorical_accuracy: 0.8847\n",
      "\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 40/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0208 - categorical_accuracy: 0.9957 - val_loss: 0.4548 - val_categorical_accuracy: 0.8708\n",
      "\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 41/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0049 - categorical_accuracy: 0.9986 - val_loss: 1.1048 - val_categorical_accuracy: 0.7486\n",
      "\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 42/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0165 - categorical_accuracy: 0.9972 - val_loss: 0.2019 - val_categorical_accuracy: 0.9167\n",
      "\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 43/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0120 - categorical_accuracy: 0.9984 - val_loss: 0.2730 - val_categorical_accuracy: 0.8986\n",
      "\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 44/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0055 - categorical_accuracy: 0.9991 - val_loss: 0.4162 - val_categorical_accuracy: 0.8889\n",
      "\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 45/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0182 - categorical_accuracy: 0.9962 - val_loss: 0.4000 - val_categorical_accuracy: 0.9278\n",
      "\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 46/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0107 - categorical_accuracy: 0.9984 - val_loss: 0.4325 - val_categorical_accuracy: 0.8542\n",
      "\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 47/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0110 - categorical_accuracy: 0.9988 - val_loss: 0.4573 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 48/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0297 - categorical_accuracy: 0.9957 - val_loss: 1.0599 - val_categorical_accuracy: 0.8847\n",
      "\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 49/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0169 - categorical_accuracy: 0.9972 - val_loss: 0.6383 - val_categorical_accuracy: 0.8590\n",
      "\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 50/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0035 - categorical_accuracy: 0.9991 - val_loss: 0.3793 - val_categorical_accuracy: 0.8528\n",
      "\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 51/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0173 - categorical_accuracy: 0.9977 - val_loss: 1.2481 - val_categorical_accuracy: 0.8667\n",
      "\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 52/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0028 - categorical_accuracy: 0.9995 - val_loss: 1.6796 - val_categorical_accuracy: 0.8292\n",
      "\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 53/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0114 - categorical_accuracy: 0.9974 - val_loss: 1.3070 - val_categorical_accuracy: 0.8569\n",
      "\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 54/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0119 - categorical_accuracy: 0.9976 - val_loss: 0.2836 - val_categorical_accuracy: 0.9021\n",
      "\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 55/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0059 - categorical_accuracy: 0.9988 - val_loss: 1.7233 - val_categorical_accuracy: 0.7431\n",
      "\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 56/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0264 - categorical_accuracy: 0.9972 - val_loss: 0.5798 - val_categorical_accuracy: 0.8562\n",
      "\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 57/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0056 - categorical_accuracy: 0.9990 - val_loss: 0.1797 - val_categorical_accuracy: 0.9194\n",
      "\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 58/100\n",
      "5760/5760 [==============================] - 202s 35ms/step - loss: 0.0107 - categorical_accuracy: 0.9983 - val_loss: 0.8565 - val_categorical_accuracy: 0.8736\n",
      "\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 59/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0081 - categorical_accuracy: 0.9988 - val_loss: 0.3486 - val_categorical_accuracy: 0.9299\n",
      "\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 60/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0078 - categorical_accuracy: 0.9991 - val_loss: 0.3575 - val_categorical_accuracy: 0.9167\n",
      "\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.94444\n",
      "Epoch 61/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0145 - categorical_accuracy: 0.9976 - val_loss: 0.4009 - val_categorical_accuracy: 0.9451\n",
      "\n",
      "Epoch 00061: val_categorical_accuracy improved from 0.94444 to 0.94514, saving model to NewIV3-150x150x1-3C-Run1.hdf5\n",
      "Epoch 62/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0038 - categorical_accuracy: 0.9997 - val_loss: 0.0550 - val_categorical_accuracy: 0.9833\n",
      "\n",
      "Epoch 00062: val_categorical_accuracy improved from 0.94514 to 0.98333, saving model to NewIV3-150x150x1-3C-Run1.hdf5\n",
      "Epoch 63/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0140 - categorical_accuracy: 0.9976 - val_loss: 0.4600 - val_categorical_accuracy: 0.8903\n",
      "\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 64/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0055 - categorical_accuracy: 0.9986 - val_loss: 0.4341 - val_categorical_accuracy: 0.8979\n",
      "\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 65/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0034 - categorical_accuracy: 0.9993 - val_loss: 1.0727 - val_categorical_accuracy: 0.8882\n",
      "\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 66/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 7.5582e-04 - categorical_accuracy: 0.9998 - val_loss: 1.0608 - val_categorical_accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 67/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0073 - categorical_accuracy: 0.9988 - val_loss: 0.7285 - val_categorical_accuracy: 0.8604\n",
      "\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 68/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0054 - categorical_accuracy: 0.9990 - val_loss: 0.3633 - val_categorical_accuracy: 0.9174\n",
      "\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 69/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0066 - categorical_accuracy: 0.9991 - val_loss: 0.3290 - val_categorical_accuracy: 0.9125\n",
      "\n",
      "Epoch 00069: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 70/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0120 - categorical_accuracy: 0.9983 - val_loss: 0.4431 - val_categorical_accuracy: 0.9097\n",
      "\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 71/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0065 - categorical_accuracy: 0.9995 - val_loss: 0.1327 - val_categorical_accuracy: 0.9549\n",
      "\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 72/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0051 - categorical_accuracy: 0.9997 - val_loss: 0.6085 - val_categorical_accuracy: 0.8701\n",
      "\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 73/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0011 - categorical_accuracy: 0.9997 - val_loss: 0.6145 - val_categorical_accuracy: 0.9167\n",
      "\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 74/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0060 - categorical_accuracy: 0.9995 - val_loss: 0.7411 - val_categorical_accuracy: 0.9139\n",
      "\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 75/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0104 - categorical_accuracy: 0.9986 - val_loss: 0.3333 - val_categorical_accuracy: 0.9083\n",
      "\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 76/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0078 - categorical_accuracy: 0.9990 - val_loss: 1.4505 - val_categorical_accuracy: 0.8597\n",
      "\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 77/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0057 - categorical_accuracy: 0.9997 - val_loss: 0.5245 - val_categorical_accuracy: 0.8847\n",
      "\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 78/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0065 - categorical_accuracy: 0.9991 - val_loss: 0.7355 - val_categorical_accuracy: 0.8861\n",
      "\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 79/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0010 - categorical_accuracy: 0.9997 - val_loss: 0.4463 - val_categorical_accuracy: 0.9174\n",
      "\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 80/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0044 - categorical_accuracy: 0.9993 - val_loss: 0.8763 - val_categorical_accuracy: 0.8931\n",
      "\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 81/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0089 - categorical_accuracy: 0.9990 - val_loss: 0.9880 - val_categorical_accuracy: 0.8806\n",
      "\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 82/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0039 - categorical_accuracy: 0.9995 - val_loss: 0.3926 - val_categorical_accuracy: 0.9049\n",
      "\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 83/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 3.4063e-05 - categorical_accuracy: 1.0000 - val_loss: 0.9764 - val_categorical_accuracy: 0.8938\n",
      "\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 84/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0149 - categorical_accuracy: 0.9986 - val_loss: 0.1389 - val_categorical_accuracy: 0.9528\n",
      "\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 85/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0010 - categorical_accuracy: 0.9998 - val_loss: 0.2860 - val_categorical_accuracy: 0.9326\n",
      "\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 86/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0109 - categorical_accuracy: 0.9990 - val_loss: 0.2740 - val_categorical_accuracy: 0.9229\n",
      "\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 87/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0041 - categorical_accuracy: 0.9997 - val_loss: 0.7833 - val_categorical_accuracy: 0.8951\n",
      "\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 88/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0155 - categorical_accuracy: 0.9986 - val_loss: 0.2678 - val_categorical_accuracy: 0.9250\n",
      "\n",
      "Epoch 00088: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 89/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0114 - categorical_accuracy: 0.9983 - val_loss: 0.7677 - val_categorical_accuracy: 0.9118\n",
      "\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 90/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0032 - categorical_accuracy: 0.9997 - val_loss: 0.8036 - val_categorical_accuracy: 0.9090\n",
      "\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 91/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 7.6675e-04 - categorical_accuracy: 0.9998 - val_loss: 0.7380 - val_categorical_accuracy: 0.9229\n",
      "\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 92/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0092 - categorical_accuracy: 0.9988 - val_loss: 0.6246 - val_categorical_accuracy: 0.9097\n",
      "\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 93/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0037 - categorical_accuracy: 0.9991 - val_loss: 1.1159 - val_categorical_accuracy: 0.8451\n",
      "\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 94/100\n",
      "5760/5760 [==============================] - 203s 35ms/step - loss: 0.0075 - categorical_accuracy: 0.9986 - val_loss: 0.2184 - val_categorical_accuracy: 0.9271\n",
      "\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 95/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 7.1039e-04 - categorical_accuracy: 0.9998 - val_loss: 1.5070 - val_categorical_accuracy: 0.7160\n",
      "\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 96/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0108 - categorical_accuracy: 0.9991 - val_loss: 1.6002 - val_categorical_accuracy: 0.8326\n",
      "\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 97/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0026 - categorical_accuracy: 0.9991 - val_loss: 1.1915 - val_categorical_accuracy: 0.8854\n",
      "\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 98/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0104 - categorical_accuracy: 0.9984 - val_loss: 1.6121 - val_categorical_accuracy: 0.8604\n",
      "\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 99/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0168 - categorical_accuracy: 0.9983 - val_loss: 1.1282 - val_categorical_accuracy: 0.8556\n",
      "\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.98333\n",
      "Epoch 100/100\n",
      "5760/5760 [==============================] - 204s 35ms/step - loss: 0.0047 - categorical_accuracy: 0.9993 - val_loss: 0.8479 - val_categorical_accuracy: 0.9146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.98333\n"
     ]
    }
   ],
   "source": [
    "#Executing the model\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    validation_data = (X_test, y_test), \n",
    "                    shuffle         = True,\n",
    "                    epochs          = epochs, \n",
    "                    verbose         = 1, \n",
    "                    batch_size      = batchsize, \n",
    "                    callbacks       =[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
